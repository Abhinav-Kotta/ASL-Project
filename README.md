# ASL-Project
 Using MediaPipe to detect different sign language gestures.

## Stuff You Need:
 1. Kaggle Dataset: https://www.kaggle.com/datasets/grassknoted/asl-alphabet  
 **Note:** draw_landmarks.py processes whatever files you give it. So it can take up to an hour to annotate the dataset
 
## Task List:
To mark a task as complete, type an 'x' between the square brackets while editing this README file
- [ ] Fix the bug with in draw_landmarks.py
  - While running  the draw_landmarks.py the annotated files have to be actively put into another directory solely for annotated images (same as the file structure of       the original dataset).
- [ ] Figure out why the model can't detect test images properly
  - Ask Mr. Zaman
- [ ] Create a demo application: follow the tutorial below  and refactor the code (around the first half of the video)
  - https://www.youtube.com/watch?v=k2EahPgl0ho&t=17s&ab_channel=Murtaza%27sWorkshop-RoboticsandAI
- [ ] Create Google Cloud account and incorporate with our dataset
make it compatible with python: watch this playlist:
  - https://youtube.com/playlist?list=PL3JVwFmb_BnTamTxXbmlwpspYdpmaHdbz

# ASL-Project
 Using MediaPipe to detect different sign language gestures.

## Stuff You Need:
 1. Kaggle Dataset: https://www.kaggle.com/datasets/grassknoted/asl-alphabet  
 **Note:** draw_landmarks.py processes whatever files you give it. So it can take up to an hour to annotate the dataset
 
## Task List:
- [ ] Finish automating annotations
  - While running  the draw_landmarks.py the annotated files have to be actively put into another directory solely for annotated images (same as the file structure of       the original dataset).
- [ ] Incorporate more data
  - Find more datasets of the ASL alphabet (more variety of images required) and combine them
- [ ] Create a demo application: follow the tutorial below  and refactor the code (around the first half of the video)
  - https://www.youtube.com/watch?v=k2EahPgl0ho&t=17s&ab_channel=Murtaza%27sWorkshop-RoboticsandAI
- [ ] Find storage places for data
  - For example: AWS, Google Cloud, etc.
